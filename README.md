````markdown
<h1 align="center">ğŸš€ Tiny-LLM: Shakespearean Text Generator</h1>

<p align="center">
  <img src="https://img.shields.io/github/stars/Tamaghnatech/Tiny-LLM?style=social" alt="Stars">
  <img src="https://img.shields.io/github/forks/Tamaghnatech/Tiny-LLM?style=social" alt="Forks">
  <img src="https://img.shields.io/github/issues/Tamaghnatech/Tiny-LLM" alt="Issues">
  <img src="https://img.shields.io/github/license/Tamaghnatech/Tiny-LLM" alt="License">
</p>

---

ğŸ­ **Tiny-LLM** is a *local-first* mini language model that generates Shakespearean, poetic, and surreal text using a **Transformer**, trained from scratch on the *Complete Works of Shakespeare*.

ğŸ’» With **Gradio UI** and **CLI** modes, it's plug-n-play magic â€” write prompts, tune temperature, toggle light/dark themes, and download your creations in seconds.

ğŸŒ **Try it on Hugging Face Spaces**:  
ğŸ”— [https://huggingface.co/spaces/Tamaghnatech/Tiny-LLM](https://huggingface.co/spaces/Tamaghnatech/Tiny-LLM)

---

## ğŸ“¦ Model Download Required (for Local Use)

Due to repo size limits, the trained model isn't bundled here.

ğŸ“¥ **[Download transformer_final.pt from Google Drive](https://drive.google.com/file/d/1HanIwaT0_sILx3-jDXfmmgYqUfHiI_S-/view?usp=sharing)**  
ğŸ“ Save it in:

```bash
Tiny-LLM/
â””â”€â”€ models/
    â””â”€â”€ transformer_final.pt
````

---

## ğŸ§  Tiny-LLM: From Prompt to Poetry

> Built from scratch using PyTorch and love â¤ï¸
> No Hugging Face pretrained models. No shortcuts. Just math, code, and Shakespeare.

---

## ğŸ“– Project Evolution

### 1. ğŸ§ª Started Small

* Dataset: `input.txt` â€” a small set of Shakespearean lines
* Trained LSTM and GRU models to generate characters

### 2. ğŸ“š Dataset Expansion

* Downloaded the full *Shakespeare Plays Corpus* from Kaggle
* Cleaned and stored as `input_large.txt`

### 3. ğŸ§± Built Transformer from Scratch

* 8 layers, 8 heads, 512 embedding dim
* Block size: 256
* Trained on GPU (100 steps)

### 4. ğŸ“Ÿ Created CLI Tool

* `generate_text.py` for terminal-based text generation

### 5. ğŸ¨ Designed Gradio Web App

* Real-time generation with sliders for Temperature, Top-k, and Length
* Light/Dark mode, session logs, model insights

---

## ğŸ§ª W\&B Dashboard

All training experiments were tracked using Weights & Biases:

ğŸ”— [View Project Dashboard](https://wandb.ai/nagtamaghna-oxford-vision-and-sensor-technology/tiny-llm)
ğŸ“ˆ [Transformer Run](https://wandb.ai/nagtamaghna-oxford-vision-and-sensor-technology/tiny-llm/runs/9000xl8r)

---

## ğŸ—‚ Project Structure

```bash
Tiny-LLM/
â”œâ”€â”€ app.py                  # Gradio interface
â”œâ”€â”€ generate_text.py        # CLI generator
â”œâ”€â”€ trainer_transformer.py  # Transformer training loop
â”œâ”€â”€ prepare_dataset.py      # Dataset cleaner
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input.txt
â”‚   â”œâ”€â”€ input_large.txt
â”‚   â””â”€â”€ Shakespeare_data.csv
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ transformer_final.pt  âœ…
â”‚
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ model_transformer.py
â”‚   â”œâ”€â”€ model_lstm.py
â”‚   â”œâ”€â”€ model_gru.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ tokenizer_bpe.py (WIP)
â”‚
â”œâ”€â”€ logs/                  # Session outputs
â”œâ”€â”€ notebooks/             # Jupyter breakdowns
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Hyperparameters

| Name           | Value       |
| -------------- | ----------- |
| Model Type     | Transformer |
| Layers         | 8           |
| Heads          | 8           |
| Embedding Size | 512         |
| Block Size     | 256         |
| Tokenizer      | Char-level  |
| Optimizer      | AdamW       |
| Steps Trained  | 100         |

---

## ğŸ’» Run Locally

```bash
git clone https://github.com/Tamaghnatech/Tiny-LLM.git
cd Tiny-LLM

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

Then, place the model inside `models/` and launch:

```bash
python app.py
```

---

## ğŸ”¥ Gradio Features

* ğŸ”¹ Prompt input box
* ğŸ”¢ Length slider (50â€“1000)
* ğŸŒ¡ï¸ Temperature control (creativity)
* ğŸ¯ Top-k sampling
* ğŸŒ“ Light/Dark toggle
* ğŸ§  Model explanation
* ğŸ“œ Prompt history
* ğŸ’¾ Downloadable output
* ğŸ§­ Timeline + Project overview

---

## ğŸ§ª Use from Terminal

```bash
python generate_text.py
```

Youâ€™ll be asked for:

* Prompt
* Length
* Temperature
* Top-k

Result prints in console.

---

## ğŸ› ï¸ Dev Roadmap

* [x] Character-level LSTM & GRU models
* [x] Train Transformer from scratch
* [x] Gradio + CLI interfaces
* [x] Weights & Biases integration
* [x] Hugging Face demo deployment
* [ ] Byte Pair Encoding (BPE)
* [ ] Attention visualization
* [ ] Language toggle (Bengali, English, Hindi, German)
* [ ] Docker + PyPI support
* [ ] Long-context training

---

## ğŸ‘¨â€ğŸ’» Author

**Tamaghna Nag**
Founder of NovalQ | ML Engineer | Shakespeare Whisperer

* ğŸ”— [Portfolio](https://tamaghnatech.in)
* ğŸ™ [GitHub](https://github.com/Tamaghnatech)
* ğŸ“Š [W\&B Project](https://wandb.ai/nagtamaghna-oxford-vision-and-sensor-technology/tiny-llm)

---

## ğŸ’¬ Final Word

> â€œA tiny model built on timeless literature.
> Proof that even small things, when trained well, can sound divine.â€

---

### ğŸª„ Fork It. Prompt It. Publish It.

ğŸ”¥ Star the repo if you like the effort and [try the app on Hugging Face](https://huggingface.co/spaces/Tamaghnatech/Tiny-LLM)!

```

